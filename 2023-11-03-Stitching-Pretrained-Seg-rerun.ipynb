{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DAEDALUS â€“ Distributed and Automated Evolutionary Deep Architecture Learning with Unprecedented Scalability\n",
    "\n",
    "This research code was developed as part of the research programme Open Technology Programme with project number 18373, which was financed by the Dutch Research Council (NWO), Elekta, and Ortec Logiqcare.\n",
    "\n",
    "Project leaders: Peter A.N. Bosman, Tanja Alderliesten\n",
    "Researchers: Alex Chebykin, Arthur Guijt, Vangelis Kostoulas\n",
    "Main code developer: Arthur Guijt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitching Segmentation Models\n",
    "\n",
    "Quoting from \"Rethinking Atrous Convolution for Semantic Image Segmentation\":\n",
    "> We evaluate the proposed models on the PASCAL VOC 2012 semantic segmentation benchmark [ 20] which contains 20 foreground object classes and one background class. The original dataset contains 1, 464 (train), 1, 449 (val), and\n",
    "1, 456 (test) pixel-level labeled images for training, validation, and testing, respectively. The dataset is augmented by\n",
    "the extra annotations provided by [ 29 ], resulting in 10, 582 (trainaug) training images. The performance is measured in\n",
    "terms of pixel intersection-over-union (IOU) averaged across the 21 classes.\n",
    "\n",
    "So the VOC dataset may be used.\n",
    "\n",
    "Furthermore, the pretrained models seem to be trained on COCO-using-VOC-labels, we might want to figure that out, too.\n",
    "\n",
    "Alternative: MONAI for Medical Decathlon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recomb.problems as problems\n",
    "problem = problems.VOCSegmentationProblem(root=\"<add-dataset-folder>\")\n",
    "# problem.ensure_downloaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as thd\n",
    "import torchvision.models.segmentation as segmentation_models\n",
    "import recomb.layers as ly\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import recomb.cx as cx\n",
    "import recomb.layers as ly\n",
    "import recomb.problems as problems\n",
    "from recomb.cx import forward_get_all_feature_maps, construct_trained_cx_network_stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thd.CocoDetection(\".\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trsf = segmentation_models.DeepLabV3_MobileNet_V3_Large_Weights.COCO_WITH_VOC_LABELS_V1.transforms()\n",
    "from torch.utils.data import DataLoader\n",
    "# d_train, _, _ = problem.load_problem_dataset(transform_train=trsf, transform_validation=trsf)\n",
    "d_train = problem.get_dataset_train()\n",
    "# d_train.transform = trsf\n",
    "dl_train = DataLoader(d_train)\n",
    "it_train = iter(dl_train)\n",
    "for _ in range(5):\n",
    "    X, Y = next(it_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = X.shape\n",
    "in_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_shape = Y.shape\n",
    "out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained with weights COCO_WITH_VOC_LABELS_V1\n",
    "model_a = segmentation_models.deeplabv3_mobilenet_v3_large(\n",
    "    weights=torchvision.models.segmentation.DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT\n",
    ")\n",
    "model_a.eval()\n",
    "\n",
    "model_b = segmentation_models.deeplabv3_resnet50(\n",
    "    weights=torchvision.models.segmentation.DeepLabV3_ResNet50_Weights.DEFAULT\n",
    ")\n",
    "model_b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gca = ly.trace_network(model_a, in_shape, verbose=True).to_neural_net_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, Image\n",
    "with open(\"g.dot\", \"w\") as f:\n",
    "    gca.to_dot(f, include_ord_label=True)\n",
    "! dot g.dot -Tpng -og.png\n",
    "! dot g.dot -Tsvg -og.svg\n",
    "# Image(\"g.png\")\n",
    "SVG(\"g.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = problem.get_dataset_train()\n",
    "# d_train.transform = trsf\n",
    "dl_train = DataLoader(d_train)\n",
    "it_train = iter(dl_train)\n",
    "next(it_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# d_train, _, _ = problem.load_problem_dataset(transform_train=trsf, transform_validation=trsf)\n",
    "d_train = problem.get_dataset_train()\n",
    "# d_train.transform = trsf\n",
    "dl_train = DataLoader(d_train)\n",
    "it_train = iter(dl_train)\n",
    "for _ in range(25):\n",
    "    X, Y = next(it_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origout = model_a(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gca.verbose = True\n",
    "gcaout = gca(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(origout[\"out\"][0, ...].detach()- gcaout[\"out\"][0, ...].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subst_255_nan(t):\n",
    "    return t.where(t != 255, torch.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4)\n",
    "axs[0].imshow(X[0, ...].permute(1, 2, 0))\n",
    "axs[1].imshow(subst_255_nan(Y[0, 0, ...]))\n",
    "axs[2].imshow(origout[\"out\"][0, ...].detach().argmax(dim=0))\n",
    "axs[3].imshow(gcaout[\"out\"][0, ...].detach().argmax(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as plye\n",
    "plye.imshow(origout[\"out\"][0, ...].detach().argmax(dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origout[\"out\"] - gcaout[\"out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origout[\"aux\"] - gcaout[\"aux\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcb = ly.trace_network(model_b, in_shape).to_neural_net_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "with open(\"g.dot\", \"w\") as f:\n",
    "    gcb.to_dot(f, include_ord_label=True)\n",
    "! dot g.dot -Tsvg -og.png\n",
    "SVG(\"g.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recomb.problems as problems\n",
    "import importlib\n",
    "importlib.reload(problems)\n",
    "problem = problems.VOCSegmentationProblem(root=\"<add-dataset-folder>\", batched_validation=True)\n",
    "# problem.ensure_downloaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetIndividual = problems.NeuralNetIndividual\n",
    "o_a = NeuralNetIndividual(model_a)\n",
    "neti_b = NeuralNetIndividual(gcb)\n",
    "o_b = NeuralNetIndividual(model_b)\n",
    "neti_b = NeuralNetIndividual(gcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RECOMB_NUM_DATALOADER_WORKERS\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.evaluate_network(dev, o_a, batch_size=16, objective=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.evaluate_network(dev, neti_a, batch_size=16, objective=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.evaluate_network(dev, o_b, batch_size=16, objective=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.evaluate_network(dev, neti_b, batch_size=16, objective=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does ensembling provide identical results too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming dictionary output\n",
    "\n",
    "# class LinearDictAggregate(ly.ModuleT):\n",
    "#     def __init__(self, ws):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.ws = torch.nn.Parameter(torch.tensor(ws).reshape(-1), requires_grad=False)\n",
    "\n",
    "#     def get_reconstructor(self):\n",
    "#         ws = self.ws\n",
    "#         return lambda: LinearDictAggregate(ws)\n",
    "    \n",
    "#     def forward_key(self, x, k):\n",
    "        \n",
    "#         assert len(x) == len(self.ws)\n",
    "#         stacked = torch.stack([xv[k] for xv in x], dim=0)\n",
    "#         return torch.sum(stacked * self.ws.reshape([-1 if x == 0 else 1 for x in range(len(stacked.shape))]), dim=0)\n",
    "\n",
    "#     def forward(self, *x):\n",
    "#         # Note - assumes set of keys is always identical.\n",
    "#         return {\n",
    "#             k: self.forward_key(x, k)\n",
    "#             for k in x[0].keys()\n",
    "#         }\n",
    "\n",
    "# class LinearDictEnsemble(ly.ModuleT):\n",
    "#     def __init__(self, submodules, ws):\n",
    "#         super().__init__()\n",
    "#         self.submodules = torch.nn.ModuleList(submodules)\n",
    "#         self.ws = ws\n",
    "\n",
    "#     def get_reconstructor(self):\n",
    "#         ws = self.ws\n",
    "#         submodules_reconstructor = [m.get_reconstructor() for m in self.submodules]\n",
    "#         return lambda: LinearDictEnsemble([m() for m in submodules_reconstructor], ws)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         r = None\n",
    "#         for sm, w in zip(self.submodules, self.ws):\n",
    "#             o = sm(x)\n",
    "#             if r is None:\n",
    "#                 r = {k: o[k] * w for k in o.keys()}\n",
    "#             else:\n",
    "#                 for k in o.keys():\n",
    "#                     r[k] += o[k] * w\n",
    "#         return r\n",
    "\n",
    "#     def to_subgraph(self, gc: ly.GraphConstructor, feature_inputs):\n",
    "#         agg = LinearDictAggregate(self.ws)\n",
    "#         agg_inputs = [(i, sm.to_subgraph(gc, feature_inputs)) for i, sm in enumerate(self.submodules)]\n",
    "#         out = agg.to_subgraph(gc, agg_inputs)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_be = ly.LinearDictEnsemble([model_a, model_b], [0.5, 0.5])\n",
    "neti_be = NeuralNetIndividual(net_be)\n",
    "torch.manual_seed(42)\n",
    "problem.evaluate_network(dev, neti_be, batch_size=16, objective=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "net_be = ly.LinearDictEnsemble([gca, gcb], [0.5, 0.5]).to_graph()\n",
    "with open(\"g.dot\", \"w\") as f:\n",
    "    net_be.to_dot(f, include_ord_label=True)\n",
    "! dot g.dot -Tsvg -og.png\n",
    "SVG(\"g.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_be = ly.LinearDictEnsemble([gca, gcb], [0.5, 0.5]).to_graph()\n",
    "neti_be = NeuralNetIndividual(net_be)\n",
    "torch.manual_seed(42)\n",
    "problem.evaluate_network(dev, neti_be, batch_size=16, objective=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib \n",
    "import recomb.cx as cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the training dataset to avoid training on the validation data\n",
    "# importlib.reload(problems)\n",
    "dataset = problem.get_dataset_train()\n",
    "\n",
    "# Grab an item from a dataloader for use in the forward pass\n",
    "from torch.utils.data import DataLoader\n",
    "dl = DataLoader(dataset)\n",
    "dli = iter(dl)\n",
    "X, _y = next(dli)\n",
    "\n",
    "for p in gca.parameters():\n",
    "    p.requires_grad_(False)\n",
    "for p in gcb.parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "stitched = cx.construct_trained_cx_network_stitching(\n",
    "    dataset=dataset,\n",
    "    dev=dev,\n",
    "    net_a=gca,\n",
    "    net_b=gcb,\n",
    "    X_in_many=X,\n",
    "    ensemblers=[ly.LinearDictAggregate([0.5, 0.5])],\n",
    "    compute_similarity=cx.compute_mock_similarity,\n",
    "    feature_shape_should_match=False,\n",
    "    batch_size=batch_size,\n",
    "\n",
    "    pretrain_cx_network = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stitched[1].joiners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "with open(\"g.dot\", \"w\") as f:\n",
    "    stitched[0].to_dot(f, include_ord_label=True)\n",
    "! dot g.dot -Tsvg -og.png\n",
    "SVG(\"g.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(problems)\n",
    "problem = problems.VOCSegmentationProblem(root=\"<add-dataset-folder>\")\n",
    "# problem.ensure_downloaded()\n",
    "dataset = problem.get_dataset_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gca.cpu()\n",
    "gcb.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(False)\n",
    "batch_size = 4 # note - 16 is too large for this network\n",
    "# would need to use checkpointing.\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"./logs/train-stitchseg-redo\")\n",
    "\n",
    "stitched = cx.construct_trained_cx_network_stitching(\n",
    "    dataset=dataset,\n",
    "    dev=dev,\n",
    "    net_a=gca,\n",
    "    net_b=gcb,\n",
    "    X_in_many=X,\n",
    "    ensemblers=[ly.LinearDictAggregate([0.5, 0.5])],\n",
    "    compute_similarity=cx.compute_mock_similarity,\n",
    "    feature_shape_should_match=False,\n",
    "    num_samples_pretrain = 128, # 16384,\n",
    "    batch_size=batch_size,\n",
    "\n",
    "    pretrain_cx_network = True,\n",
    "    immediately_backprop = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16384/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for es in stitched[1].joiners:\n",
    "    for e in es:\n",
    "        e.agg = None\n",
    "stitched[1].output_switch.agg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_simpl = (stitched[0], cx.SitchingInfo(stitched[1].joiners, stitched[1].output_switch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(stitched_simpl, \"stitched-seg.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_simpl = torch.load(\"stitched-seg.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitchnet, stitchinfo = stitched_simpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "with open(\"g.dot\", \"w\") as f:\n",
    "    stitchnet.to_dot(f, include_ord_label=True)\n",
    "! dot g.dot -Tsvg -og.png\n",
    "SVG(\"g.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cx_connectivity_graph(cx_net: ly.NeuralNetGraph):\n",
    "    g = cx_net.graph.copy()\n",
    "    o = g.topological_sorting()\n",
    "    idxs_to_remove = []\n",
    "    edges_to_add = []\n",
    "    for i in o:\n",
    "        vi = g.vs[i]\n",
    "\n",
    "        is_edge_case = False\n",
    "        if len(vi.in_edges()) == 0:\n",
    "            # edge case - input node\n",
    "            vi[\"cxs\"] = set([vi.index])\n",
    "            is_edge_case = True\n",
    "        \n",
    "        if len(vi.out_edges())  == 0 and vi[\"module\"] < 0:\n",
    "            # edge case - output node\n",
    "            vi[\"cxs\"] = set([vi.index])\n",
    "            is_edge_case = True\n",
    "        \n",
    "        is_cxn = isinstance(cx_net.submodules[vi[\"module\"]], cx.CXN)\n",
    "        cxs_in = set()\n",
    "        # i.e., where does this CXN link to via what node?\n",
    "        affinity_mappings = {}\n",
    "        for e in vi.in_edges():\n",
    "            cxs_in.update(g.vs[e.source][\"cxs\"])\n",
    "            if is_cxn:\n",
    "                affinity_set = affinity_mappings.get(e[\"socket\"], set())\n",
    "                affinity_set.update(g.vs[e.source][\"cxs\"])\n",
    "                affinity_mappings[e[\"socket\"]] = affinity_set\n",
    "        if is_cxn:\n",
    "            edges_to_add += [(s, i, socket) for (socket, cxn_set) in affinity_mappings.items() for s in cxn_set]\n",
    "            vi[\"cxs\"] = set([i])\n",
    "        elif not is_edge_case:\n",
    "            vi[\"cxs\"] = cxs_in\n",
    "            idxs_to_remove.append(i)\n",
    "\n",
    "    g.add_edges([t[:2] for t in edges_to_add], attributes=dict(socket=[t[2] for t in edges_to_add]))\n",
    "    g.delete_vertices(idxs_to_remove)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxg = get_cx_connectivity_graph(stitchnet)\n",
    "fig, ax = plt.subplots()\n",
    "graph_layout = cxg.layout(\"sugiyama\")\n",
    "graph_layout.rotate(-90)\n",
    "ig.plot(cxg, target=ax, layout=graph_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_primary_line_membership(cx_graph, verbose=False):\n",
    "    \"\"\"\n",
    "    Recover for each vertex in the crossover point graph to which networks they originally belonged\n",
    "    assuming that input 0 to each crossover point maintains the original graph.\n",
    "\n",
    "    (Note that this method may be skipped by tracking the original origin during stitching and assigning\n",
    "     membership accordingly.)\n",
    "    \"\"\"\n",
    "    # Initialize graph membership to each on their own\n",
    "    cx_graph.vs[\"og\"] = range(len(cx_graph.vs))\n",
    "    # For input & output add a placeholder\n",
    "    cx_graph.vs[0][\"og\"] = -1\n",
    "    cx_graph.vs[1][\"og\"] = -1\n",
    "    \n",
    "    # Go over the graph in a topological order\n",
    "    ordering = cx_graph.topological_sorting()\n",
    "    for o in ordering:\n",
    "        v = cx_graph.vs[o]\n",
    "        # skip over input & output nodes\n",
    "        if v[\"og\"] == -1: continue\n",
    "        # Loop over the elements with a similar affinity set and get their corresponding assignment.\n",
    "        new_og = v[\"og\"]\n",
    "        same_origin_nodes = [e.source for e in v.in_edges() if e[\"socket\"] == 0]\n",
    "        if verbose: print(f\"same origin: {same_origin_nodes}\")\n",
    "        # Merge identities in union-find like structure.\n",
    "        for set_elem in same_origin_nodes:\n",
    "            # print(f\"visiting {set_elem}\")\n",
    "            v_other = cx_graph.vs[set_elem]\n",
    "            if verbose: print(f\"incident edge og is {v_other['og']}\")\n",
    "            if v_other[\"og\"] == -1: continue\n",
    "            new_og = min(new_og, v_other[\"og\"])\n",
    "        if verbose: print(f\"og was {v['og']} should update to {new_og}\")\n",
    "        v[\"og\"] = new_og\n",
    "        for set_elem in same_origin_nodes:\n",
    "            # print(f\"updating {set_elem}\")\n",
    "            v_other = cx_graph.vs[set_elem]\n",
    "            if v_other[\"og\"] == -1: continue\n",
    "            v_id = cx_graph.vs[v_other[\"og\"]]\n",
    "            v_id[\"og\"] = new_og\n",
    "        if verbose: print(f\"og is now {v['og']} updated to {new_og}\")\n",
    "    # iterate union find for each element in the graph.\n",
    "    for o in ordering:\n",
    "        v = cx_graph.vs[o]\n",
    "        # if special case or identical, skip\n",
    "        if v[\"og\"] == -1: continue\n",
    "        if v[\"og\"] == o: continue\n",
    "        # otherwise track down the first identical element\n",
    "        og = v[\"og\"]\n",
    "        while True:\n",
    "            v_potential_og = cx_graph.vs[og]\n",
    "            # found it?\n",
    "            if v_potential_og[\"og\"] == -1: continue\n",
    "            if v_potential_og[\"og\"] == og: break\n",
    "            # otherwise continue down the line\n",
    "            og = v_potential_og[\"og\"]\n",
    "        # go down the line again, updating the og value accordingly.\n",
    "        l = v[\"og\"]\n",
    "        v[\"og\"] = og\n",
    "        while True:\n",
    "            v_other = cx_graph.vs[l]\n",
    "            if v_other[\"og\"] == -1: continue\n",
    "            l = v_other[\"og\"]\n",
    "            v_other[\"og\"] = og\n",
    "            if v_other[\"og\"] == l: break\n",
    "    return cx_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_primary_line_membership(cxg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxg.vs[\"og\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_parallel_set(cxg, i):\n",
    "    s = set(range(len(cxg.vs))) \n",
    "    s -= set(cxg.subcomponent(i, mode='out'))\n",
    "    s -= set(cxg.subcomponent(i, mode='in'))\n",
    "    # s.add(i)\n",
    "    return s\n",
    "\n",
    "def compute_all_parallel_set(cxg):\n",
    "    return [compute_parallel_set(cxg, i) for i in range(len(cxg.vs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_cxs = compute_all_parallel_set(cxg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from functools import partial\n",
    "def enumerate_parallel_set(g, set_idx, parallel_sets, i, verbose=False):\n",
    "    def call_funcs(lfn):\n",
    "        for fn in lfn:\n",
    "            fn()\n",
    "\n",
    "    for (set_list, restore_list) in enumerate_parallel_set_recur(g, set_idx, parallel_sets, i, None, set(), verbose=verbose):\n",
    "        yield (lambda: call_funcs(set_list)), (lambda: call_funcs(restore_list))\n",
    "\n",
    "def enumerate_parallel_set_recur(g, set_idx, parallel_sets, i, current_set=None, unpickable: set=set(), ref_og=None, verbose=False):\n",
    "    if current_set is None:\n",
    "        # Initial case - current set is the parallel set of the index we are starting with.\n",
    "        current_set = copy(parallel_sets[i])\n",
    "        ref_og = g.vs[i][\"og\"]\n",
    "        # filter current set based on a match\n",
    "        current_set = {a for a in current_set if g.vs[a][\"og\"] == ref_og}\n",
    "    else:\n",
    "        # Otherwise, update the set of uncovered elements.\n",
    "        current_set = current_set.intersection(parallel_sets[i])\n",
    "\n",
    "    if len(current_set) == 0:\n",
    "        if verbose: print(f\"base case - no other choices necessary after picking {i}\")\n",
    "        # yield setter for configuring and unconfiguring i. No other configurations necessary\n",
    "        # as there are no other branches.\n",
    "        yield [partial(set_idx, i, 1)], [partial(set_idx, i, 0)]\n",
    "        # return - as there are no more elements in the neighborhood.\n",
    "        return\n",
    "\n",
    "    # Obtain a fixed ordering of the set of leftover elements to be picked.\n",
    "    ordering = list(current_set - unpickable)\n",
    "    \n",
    "    # Find current reverse cumulative intersection.\n",
    "    # The intersection of sets picked so far provides knowledge of elements that may need\n",
    "    # to be picked to cover all branches.\n",
    "    # If we perform this operation cumulatively from the right the elements left in the\n",
    "    # set allow us to identify necessary picks.\n",
    "    # if we have the set with fixed ordering [ 1, 2, 3]\n",
    "    # and the set corresponding here are 1 -> {0, 2, 3}, 2 -> {0, 1, 3}, 3 -> {0, 1, 2}\n",
    "    # (note: the index itself is never contained within its own parallel set)\n",
    "    # In this case the sequence of sets would be\n",
    "    # [{}, {1}, {1, 2}]\n",
    "    # as the only set that does not contain {1} is the set corresponding to {1}, 1 must be picked.\n",
    "    cumulative_sets_rl = [None for _ in range(len(ordering))]\n",
    "    cumulative_sets_rl[-1] = current_set.intersection(parallel_sets[ordering[-1]])\n",
    "    required_right = {ordering[-1]}\n",
    "    for i in range(len(ordering) - 1, 0, -1):\n",
    "        el = ordering[i - 1]\n",
    "        cumulative_sets_rl[i - 1] = cumulative_sets_rl[i].intersection(parallel_sets[el])\n",
    "        # note - if an ordering[i - 1] is in cumulative_sets_rl[i], el needs to be picked if we do not\n",
    "        # pick any of the preceding elements as there are no further elements to cover this branch.\n",
    "        if ordering[i - 1] in cumulative_sets_rl[i]:\n",
    "            required_right.add(el)\n",
    "    # If we do it the other direction we can do the same thing for any following elements.\n",
    "    cumulative_sets_lr = [None for _ in range(len(ordering))]\n",
    "    cumulative_sets_lr[0] = current_set.intersection(parallel_sets[ordering[0]])\n",
    "    required_left = {ordering[0]}\n",
    "    for i in range(0, len(ordering) - 1):\n",
    "        el = ordering[i + 1]\n",
    "        cumulative_sets_lr[i + 1] = cumulative_sets_lr[i].intersection(parallel_sets[el])\n",
    "        # similar reasoning - if we pick none of the elements after this one, there would be\n",
    "        # a uncovered branch\n",
    "        if ordering[i + 1] in cumulative_sets_lr[i]:\n",
    "            required_left.add(el)\n",
    "    # Elements that are in both required sets are always to be taken.\n",
    "    always_required = required_left.intersection(required_right)\n",
    "\n",
    "    # For future additions: - if one skips elements that have already been investigated previously (i.e., \n",
    "    # elsewhere in the ordering, another indicator is important to keep track of:\n",
    "    # cumulative_sets_lr[-1] and cumulative_sets_rl[0] should always be empty sets - if they are not\n",
    "    # there exists an element that is not optional that was excluded.\n",
    "    # Probably shouldn't happen since we force always required, but just in case, handle this edge case.\n",
    "    if len(cumulative_sets_lr[-1]) != 0 or len(cumulative_sets_rl[0]) != 0:\n",
    "        if verbose: print(\"forbidden case - no choices cover all branches anymore...\")\n",
    "        return\n",
    "\n",
    "    fixed_set = [partial(set_idx, i, 1)]\n",
    "    fixed_restore = [partial(set_idx, i, 0)]\n",
    "    \n",
    "    if verbose: print(f\"in this case to cover all branches {always_required} are required\")\n",
    "    for a in always_required:\n",
    "        current_set.intersection_update(parallel_sets[a])\n",
    "        fixed_set.append(partial(set_idx, a, 1))\n",
    "        fixed_restore.append(partial(set_idx, a, 0))\n",
    "\n",
    "    if len(current_set) == 0:\n",
    "        if verbose: print(f\"fixed case - no more free choices left to make after picking {i}\")\n",
    "        yield fixed_set, fixed_restore\n",
    "    else:\n",
    "        if verbose: print(f\"recursive case for {i}\")\n",
    "        for e in current_set:\n",
    "            # consider the cases where we pick it\n",
    "            \n",
    "            print(f\"considering picking {e}\")\n",
    "            for (set_list, restore_list) in enumerate_parallel_set_recur(g, parallel_sets, e, current_set, unpickable=unpickable, ref_og=ref_og):\n",
    "                yield (fixed_set + set_list), (fixed_restore + restore_list)\n",
    "            print(f\"no longer considering picking {e}\")\n",
    "            # now - for the following picks consider the case where we not allow e to be picked anymore.\n",
    "            unpickable.add(i)\n",
    "        # to avoid issues with branching allow picking these elements again if another branch investigates them.\n",
    "        for e in current_set:\n",
    "            unpickable.remove(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_idx(i, to):\n",
    "    module_idx = cxg.vs[i]['module']\n",
    "    switch = stitchnet.submodules[module_idx]\n",
    "    switch.active = to\n",
    "    print(f\"submodule {module_idx} ({type(switch)}) active set to {to}\")\n",
    "\n",
    "\n",
    "for set_list, restore_list in enumerate_parallel_set(cxg, set_idx, parallel_cxs, 16):\n",
    "    set_list()\n",
    "    print(\"----------------------\")\n",
    "    restore_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Transform graph layout to coords\n",
    "layout_coords = np.array(graph_layout)\n",
    "vertex_coords = np.array([layout_coords[v.index] for v in cxg.vs])\n",
    "# edge_coords = [[layout_coords[e.source, :], layout_coords[e.target, :], [np.nan, np.nan]] for e in cxg.es]\n",
    "edge_coords = [[\n",
    "    layout_coords[e.source, :],\n",
    "    layout_coords[e.target, :],\n",
    "    [np.nan, np.nan],\n",
    "    ]\n",
    "    for e in cxg.es]\n",
    "edge_coords = np.array(edge_coords).reshape(-1, 2)\n",
    "\n",
    "# edge_trace = go.Scatter(x=edge_x, y=edge_y, line=dict(width=lineWidth, color=lineColor), hoverinfo='none', mode='lines')\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_coords[:, 0],\n",
    "    y=edge_coords[:, 1],\n",
    "    hoverinfo='none',\n",
    "    mode='lines+markers',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        symbol=\"arrow\",\n",
    "        angleref=\"previous\"\n",
    "        )\n",
    ")\n",
    "\n",
    "# node_trace = go.Scatter(x=node_x, y=node_y, mode='markers', hoverinfo='text', marker=dict(showscale=False, color = nodeColor, size=nodeSize))\n",
    "node_trace = go.Scatter(\n",
    "    x=vertex_coords[:, 0],\n",
    "    y=vertex_coords[:, 1],\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(showscale=False)\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "graph_layout, cxge = cxg.layout_sugiyama(return_extended_graph=True)\n",
    "# Transform graph layout to coords\n",
    "layout_coords = np.array(graph_layout)\n",
    "vertex_coords = np.array([layout_coords[v.index] for v in cxg.vs])\n",
    "# edge_coords = [[layout_coords[e.source, :], layout_coords[e.target, :], [np.nan, np.nan]] for e in cxg.es]\n",
    "edge_coords = [[\n",
    "    layout_coords[e.source, :],\n",
    "    layout_coords[e.target, :],\n",
    "    [np.nan, np.nan],\n",
    "    ]\n",
    "    for e in cxge.es]\n",
    "edge_coords = np.array(edge_coords).reshape(-1, 2)\n",
    "is_arrow_end = np.array([[0, 0, 0] if edge.target >= num_orig_nodes else [0, 10, 0] for edge in cxge.es]).ravel()\n",
    "\n",
    "num_orig_nodes = len(cxg.vs)\n",
    "# edge_trace = go.Scatter(x=edge_x, y=edge_y, line=dict(width=lineWidth, color=lineColor), hoverinfo='none', mode='lines')\n",
    "edge_trace = go.Scatter(\n",
    "    # note: coords are transposed.\n",
    "    x=edge_coords[:, 1],\n",
    "    y=edge_coords[:, 0],\n",
    "    hoverinfo='none',\n",
    "    mode='lines+markers',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        angleref=\"previous\",\n",
    "        symbol=\"arrow\",\n",
    "        ),\n",
    "    marker_size = is_arrow_end,\n",
    ")\n",
    "\n",
    "def color_table(ogv):\n",
    "    if ogv == 2: return 'red'\n",
    "    if ogv == 3: return 'blue'\n",
    "    return 'white'\n",
    "\n",
    "# node_trace = go.Scatter(x=node_x, y=node_y, mode='markers', hoverinfo='text', marker=dict(showscale=False, color = nodeColor, size=nodeSize))\n",
    "node_trace = go.Scatter(\n",
    "    # note: coords are transposed.\n",
    "    x=vertex_coords[:, 1],\n",
    "    y=vertex_coords[:, 0],\n",
    "    marker_color = [color_table(og) for og in cxg.vs[\"og\"]],\n",
    "    mode='markers',\n",
    "    # hoverinfo='text',\n",
    "    marker=dict(showscale=False)\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                showlegend=False,\n",
    "                # hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_arrow_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitchnet.eval()\n",
    "stitchnet(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed computational cost info\n",
    "import torchinfo\n",
    "import recomb.eval_costs as ec\n",
    "cost_summary = torchinfo.summary(stitchnet, input_data=[X])\n",
    "ec.embed_cost_stats_in_model(cost_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((\"The stitched neural network has \"\n",
    "       f\"{len(stitchinfo.joiners)} matches\"\n",
    "       ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate predetermined neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "stitchnet.cpu()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this network will cost  70200072306 mul-adds and approx 3032042904\n",
    "# this network will cost 180146119266 mul-adds and approx 3761352936 of memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "with open(\"g.dot\", \"w\") as f:\n",
    "    stitchnet.to_dot(f, include_ord_label=True)\n",
    "! dot g.dot -Tsvg -og.png\n",
    "SVG(\"g.png\")\n",
    "\n",
    "\n",
    "total_mult_adds, total_bytes = ec.evaluate_compute_cost(stitchnet)\n",
    "print(f\"this network will cost {total_mult_adds} mul-adds and approx {total_bytes} of memory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitchinfo.output_switch.active = 2\n",
    "stitchinfo.output_switch.simplify = True\n",
    "\n",
    "for j in stitchinfo.joiners:\n",
    "        j[0].active = 0\n",
    "        j[1].active = 0\n",
    "        j[0].simplify = True\n",
    "        j[1].simplify = True\n",
    "\n",
    "dev = torch.device(\"cuda:1\")\n",
    "\n",
    "stitchnet_pruned = stitchnet.to_graph()\n",
    "stitchnet_pruned.prune_unused()\n",
    "\n",
    "total_mult_adds, total_bytes = ec.evaluate_compute_cost(stitchnet_pruned)\n",
    "print(f\"this network will cost {total_mult_adds} mul-adds and approx {total_bytes} of memory\")\n",
    "\n",
    "\n",
    "from IPython.display import SVG\n",
    "with open(\"g.dot\", \"w\") as f:\n",
    "    stitchnet_pruned.to_dot(f, include_ord_label=True)\n",
    "! dot g.dot -Tsvg -og.png\n",
    "SVG(\"g.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = problems.VOCSegmentationProblem(\"<add-dataset-folder>\", batched_validation=True, validation_sample_limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:1\")\n",
    "# Evaluate reference networks\n",
    "reference_q = []\n",
    "stitchinfo.output_switch.active = 2\n",
    "stitchinfo.output_switch.simplify = True\n",
    "\n",
    "for j in stitchinfo.joiners:\n",
    "        j[0].active = 0\n",
    "        j[1].active = 0\n",
    "        j[0].simplify = True\n",
    "        j[1].simplify = True\n",
    "\n",
    "batch_size = 16\n",
    "stitchnet_pruned = stitchnet.to_graph()\n",
    "stitchnet_pruned.prune_unused()\n",
    "total_mult_adds, total_bytes = ec.evaluate_compute_cost(stitchnet_pruned)\n",
    "print(f\"full ensemble will cost {total_mult_adds} mul-adds and approx {total_bytes} of memory\")\n",
    "neti_os = NeuralNetIndividual(stitchnet_pruned)\n",
    "accuracy, loss = problem.evaluate_network(dev, neti_os, batch_size=batch_size, objective=\"both\")\n",
    "reference_q.append((accuracy, loss, total_bytes, total_mult_adds, cx.convert_stitcher_to_genotype(stitchinfo, stringify=False)))\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "stitchinfo.output_switch.active = 1\n",
    "stitchnet_pruned = stitchnet.to_graph()\n",
    "stitchnet_pruned.prune_unused()\n",
    "total_mult_adds, total_bytes = ec.evaluate_compute_cost(stitchnet_pruned)\n",
    "\n",
    "neti_os = NeuralNetIndividual(stitchnet_pruned)\n",
    "accuracy, loss = problem.evaluate_network(dev, neti_os, batch_size=batch_size, objective=\"both\")\n",
    "reference_q.append((accuracy, loss, total_bytes, total_mult_adds, cx.convert_stitcher_to_genotype(stitchinfo, stringify=False)))\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "stitchinfo.output_switch.active = 0\n",
    "stitchnet_pruned = stitchnet.to_graph()\n",
    "stitchnet_pruned.prune_unused()\n",
    "total_mult_adds, total_bytes = ec.evaluate_compute_cost(stitchnet_pruned)\n",
    "\n",
    "neti_os = NeuralNetIndividual(stitchnet_pruned)\n",
    "accuracy, loss = problem.evaluate_network(dev, neti_os, batch_size=batch_size, objective=\"both\")\n",
    "reference_q.append((accuracy, loss, total_bytes, total_mult_adds, cx.convert_stitcher_to_genotype(stitchinfo, stringify=False)))\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_a = []\n",
    "ensembles_b = []\n",
    "start_a_end_b = []\n",
    "start_b_end_a = []\n",
    "\n",
    "# note - usually 1, but due to the large amount of matches, this has been\n",
    "# increased so that we can evaluate blocks of solutions instead.\n",
    "step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitchinfo.output_switch.active = 2\n",
    "stitchinfo.output_switch.simplify = True\n",
    "\n",
    "dev = torch.device(\"cuda:0\")\n",
    "\n",
    "for j in stitchinfo.joiners:\n",
    "        j[0].active = 0\n",
    "        j[1].active = 0\n",
    "        j[0].simplify = True\n",
    "        j[1].simplify = True\n",
    "\n",
    "i = 0\n",
    "j = stitchinfo.joiners[i]\n",
    "j[0].active = 0\n",
    "j[1].active = 1\n",
    "\n",
    "stitchnet_pruned = stitchnet.to_graph()\n",
    "stitchnet_pruned.prune_unused()\n",
    "\n",
    "# Get compute & memory requirements\n",
    "# s = torchinfo.summary(stitchnet_pruned, input_data=[X])\n",
    "total_mult_adds, total_bytes = ec.evaluate_compute_cost(stitchnet_pruned)\n",
    "\n",
    "neti_os = NeuralNetIndividual(stitchnet_pruned)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "j[0].active = 0\n",
    "j[1].active = 0\n",
    "\n",
    "from IPython.display import SVG\n",
    "with open(\"g.dot\", \"w\") as f:\n",
    "    stitchnet_pruned.to_dot(f, include_ord_label=True)\n",
    "! dot g.dot -Tsvg -og.png\n",
    "SVG(\"g.png\")\n",
    "\n",
    "# accuracy, loss = problem.evaluate_network(dev, neti_os, batch_size=batch_size, objective=\"both\")\n",
    "# ensembles_a.append((accuracy, loss, total_bytes, total_mult_adds, cx.convert_stitcher_to_genotype(stitchinfo, stringify=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neighborhood of networks\n",
    "def evaluate_neighborhood_given_offset(offset, batch_size=16):\n",
    "    stitchinfo.output_switch.active = 2\n",
    "    stitchinfo.output_switch.simplify = True\n",
    "\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "\n",
    "    for j in stitchinfo.joiners:\n",
    "            j[0].active = 0\n",
    "            j[1].active = 0\n",
    "            j[0].simplify = True\n",
    "            j[1].simplify = True\n",
    "\n",
    "    for i in range(offset, len(stitchinfo.joiners), step):\n",
    "        j = stitchinfo.joiners[i]\n",
    "        j[0].active = 0\n",
    "        j[1].active = 1\n",
    "\n",
    "        stitchnet_pruned = stitchnet.to_graph()\n",
    "        stitchnet_pruned.prune_unused()\n",
    "\n",
    "        # Get compute & memory requirements\n",
    "        # s = torchinfo.summary(stitchnet_pruned, input_data=[X])\n",
    "        total_mult_adds, total_bytes = ec.evaluate_compute_cost(stitchnet_pruned)\n",
    "\n",
    "        neti_os = NeuralNetIndividual(stitchnet_pruned)\n",
    "        accuracy, loss = problem.evaluate_network(dev, neti_os, batch_size=batch_size, objective=\"both\")\n",
    "        ensembles_a.append((accuracy, loss, total_bytes, total_mult_adds, cx.convert_stitcher_to_genotype(stitchinfo, stringify=False)))\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        j[0].active = 0\n",
    "        j[1].active = 0\n",
    "\n",
    "    for i in range(offset, len(stitchinfo.joiners), step):\n",
    "        j = stitchinfo.joiners[i]\n",
    "        j[0].active = 1\n",
    "        j[1].active = 0\n",
    "\n",
    "        stitchnet_pruned = stitchnet.to_graph()\n",
    "        stitchnet_pruned.prune_unused()\n",
    "\n",
    "        # Get compute & memory requirements\n",
    "        # s = torchinfo.summary(stitchnet_pruned, input_data=[X])\n",
    "        total_mult_adds, total_bytes = ec.evaluate_compute_cost(stitchnet_pruned)\n",
    "\n",
    "        neti_os = NeuralNetIndividual(stitchnet_pruned)\n",
    "        accuracy, loss = problem.evaluate_network(dev, neti_os, batch_size=batch_size, objective=\"both\")\n",
    "        ensembles_b.append((accuracy, loss, total_bytes, total_mult_adds, cx.convert_stitcher_to_genotype(stitchinfo, stringify=False)))\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        j[0].active = 0\n",
    "        j[1].active = 0\n",
    "\n",
    "    stitchinfo.output_switch.active = 1\n",
    "    for i in range(offset, len(stitchinfo.joiners), step):\n",
    "        j = stitchinfo.joiners[i]\n",
    "        j[0].active = 0\n",
    "        j[1].active = 1\n",
    "\n",
    "        stitchnet_pruned = stitchnet.to_graph()\n",
    "        stitchnet_pruned.prune_unused()\n",
    "\n",
    "        # Get compute & memory requirements\n",
    "        # s = torchinfo.summary(stitchnet_pruned, input_data=[X])\n",
    "        total_mult_adds, total_bytes = ec.evaluate_compute_cost(stitchnet_pruned)\n",
    "\n",
    "        neti_os = NeuralNetIndividual(stitchnet_pruned)\n",
    "        accuracy, loss = problem.evaluate_network(dev, neti_os, batch_size=batch_size, objective=\"both\")\n",
    "        start_a_end_b.append((accuracy, loss, total_bytes, total_mult_adds, cx.convert_stitcher_to_genotype(stitchinfo, stringify=False)))\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        j[0].active = 0\n",
    "        j[1].active = 0\n",
    "\n",
    "    stitchinfo.output_switch.active = 0\n",
    "    for i in range(offset, len(stitchinfo.joiners), step):\n",
    "        j = stitchinfo.joiners[i]\n",
    "        j[0].active = 1\n",
    "        j[1].active = 0\n",
    "\n",
    "        stitchnet_pruned = stitchnet.to_graph()\n",
    "        stitchnet_pruned.prune_unused()\n",
    "\n",
    "        # Get compute & memory requirements\n",
    "        # s = torchinfo.summary(stitchnet_pruned, input_data=[X])\n",
    "        total_mult_adds, total_bytes = ec.evaluate_compute_cost(stitchnet_pruned)\n",
    "\n",
    "        neti_os = NeuralNetIndividual(stitchnet_pruned)\n",
    "        accuracy, loss = problem.evaluate_network(dev, neti_os, batch_size=batch_size, objective=\"both\")\n",
    "        start_b_end_a.append((accuracy, loss, total_bytes, total_mult_adds, cx.convert_stitcher_to_genotype(stitchinfo, stringify=False)))\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        j[0].active = 0\n",
    "        j[1].active = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - very little training performed above initially\n",
    "evaluate_neighborhood_given_offset(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_neighborhood_given_offset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_neighborhood_given_offset(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_neighborhood_given_offset(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_neighborhood_given_offset(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_neighborhood_given_offset(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_neighborhood_given_offset(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_neighborhood_given_offset(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_neighborhood_given_offset(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_neighborhood_given_offset(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema = [\"accuracy\", \"loss\", \"total bytes\", \"multiply-adds\", \"genotype\"]\n",
    "samples_reference = pl.DataFrame(reference_q, schema=df_schema).\\\n",
    "    with_columns([\n",
    "        pl.lit(pl.Series([\"ensemble\", \"b\", \"a\"])).alias(\"set\"),\n",
    "        pl.lit(False).alias(\"contains stitch\"),\n",
    "    ])\n",
    "samples_ensemble_a = pl.DataFrame(ensembles_a, schema=df_schema).\\\n",
    "    with_columns([\n",
    "        pl.lit(\"ensemble-major-a\").alias(\"set\"),\n",
    "        pl.lit(True).alias(\"contains stitch\"),\n",
    "    ])\n",
    "samples_ensemble_b = pl.DataFrame(ensembles_b, schema=df_schema).\\\n",
    "    with_columns([\n",
    "        pl.lit(\"ensemble-major-b\").alias(\"set\"),\n",
    "        pl.lit(True).alias(\"contains stitch\"),\n",
    "    ])\n",
    "samples_ab = pl.DataFrame(start_a_end_b, schema=df_schema).\\\n",
    "    with_columns([\n",
    "        pl.lit(\"stitch-a-to-b\").alias(\"set\"),\n",
    "        pl.lit(True).alias(\"contains stitch\"),\n",
    "    ])\n",
    "samples_ba = pl.DataFrame(start_b_end_a, schema=df_schema).\\\n",
    "    with_columns([\n",
    "        pl.lit(\"stitch-b-to-a\").alias(\"set\"),\n",
    "        pl.lit(True).alias(\"contains stitch\"),\n",
    "    ])\n",
    "\n",
    "samples = pl.concat([\n",
    "    samples_reference,\n",
    "    samples_ensemble_a,\n",
    "    samples_ensemble_b,\n",
    "    samples_ab,\n",
    "    samples_ba,\n",
    "], how=\"vertical_relaxed\").with_columns(\n",
    "    pl.col(\"loss\").clip(0.0, 4.0).alias(\"loss-clip\")\n",
    ")\n",
    "samples.write_ipc(\"segmentation-stitch-samples.arrow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot approximation front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pl.read_ipc(\"resnet-efficientnet-stitch-samples.arrow\")\n",
    "\n",
    "# Extract some rows of reference interest\n",
    "dfcna = samples[2]\n",
    "dfcnb = samples[1]\n",
    "dfcnens = samples[0]\n",
    "\n",
    "# \n",
    "improvement_direction = {\n",
    "    \"accuracy\": 1,\n",
    "    \"loss\": -1,\n",
    "    \"loss-clip\": -1,\n",
    "    \"total bytes\": -1,\n",
    "    \"multiply-adds\": -1,\n",
    "    # \"genotype\": 0, # -- not a criterion\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stitchinfo.joiners) * 4 * 15 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How many seconds per evaluated sample?\n",
    "# number_of_minutes = 16 * 8\n",
    "# number_of_seconds = 0\n",
    "# number_of_samples = len(samples) - 3\n",
    "# seconds_total = number_of_minutes * 60 + number_of_seconds\n",
    "# seconds_per_sample = seconds_total / number_of_samples\n",
    "\n",
    "# print(f\"spent {number_of_minutes}m{number_of_seconds}s \"\n",
    "#       f\"to evaluate {number_of_samples} samples.\\n\"\n",
    "#       f\"Resulting in a cost of {seconds_per_sample}s per sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pareto set from these points, with respect to these\n",
    "# two criteria / objectives\n",
    "c0 = \"accuracy\"\n",
    "c1 = \"multiply-adds\"\n",
    "\n",
    "samples_pareto = (samples.lazy()\n",
    "    .sort(c0, descending=improvement_direction[c0] > 0)\n",
    "    .with_columns((pl.col(c1) * -improvement_direction[c1]).alias(\"c1-min\"))\n",
    "    .with_columns((pl.col(\"c1-min\")).cummin().alias(\"mv\"))\n",
    "    .with_columns((pl.col(\"c1-min\") < pl.col(\"mv\").shift(1)).alias(\"is pareto\")).fill_null(True)\n",
    "    .filter(pl.col(\"is pareto\"))\n",
    ").collect()\n",
    "\n",
    "samples_pareto_stitch_only = (samples.lazy()\n",
    "    .filter(pl.col(\"contains stitch\"))\n",
    "    .sort(c0, descending=improvement_direction[c0] > 0)\n",
    "    .with_columns((pl.col(c1) * -improvement_direction[c1]).alias(\"c1-min\"))\n",
    "    .with_columns((pl.col(\"c1-min\")).cummin().alias(\"mv\"))\n",
    "    .with_columns((pl.col(\"c1-min\") < pl.col(\"mv\").shift(1)).alias(\"is pareto\")).fill_null(True)\n",
    "    .filter(pl.col(\"is pareto\"))\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sn, df in samples.filter(pl.col(\"contains stitch\")).group_by(\"set\", maintain_order=True):\n",
    "    plt.scatter(df[c0], df[c1], label=sn, s=1.0)\n",
    "\n",
    "plt.scatter(samples_pareto[c0], samples_pareto[c1], alpha=0.4, marker=\"s\", color=\"grey\")\n",
    "plt.scatter(samples_pareto_stitch_only[c0], samples_pareto_stitch_only[c1], s=20.0, alpha=0.5, color=\"grey\")\n",
    "\n",
    "plt.scatter(dfcna[c0], dfcna[c1], label=\"a\", marker='x')\n",
    "plt.scatter(dfcnb[c0], dfcnb[c1], label=\"b\", marker='x')\n",
    "plt.scatter(dfcnens[c0], dfcnens[c1], label=\"ensemble\", marker='x')\n",
    "\n",
    "def get_direction_arrow(c):\n",
    "    return '->' if improvement_direction[c] > 0 else '<-'\n",
    "\n",
    "plt.xlabel(f\"{c0} ({get_direction_arrow(c0)})\")\n",
    "plt.ylabel(f\"{c1} ({get_direction_arrow(c1)})\")\n",
    "plt.legend(loc='upper left',\n",
    "           bbox_to_anchor=(1.0, 1.0),\n",
    "           fancybox=False,\n",
    "           shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Potential Points of Improvement?**\n",
    "1. Pretrain for longer? (e.g. specific stopping condition?)\n",
    "2. Train using actual loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(samples[c0], samples[c1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some test evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2 = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate original networks\n",
    "neti_a = NeuralNetIndividual(gca)\n",
    "neti_b = NeuralNetIndividual(gcb)\n",
    "problem.evaluate_network(dev2, neti_a, objective=\"both\"),\\\n",
    "    problem.evaluate_network(dev, neti_b, objective=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitchneti = NeuralNetIndividual(stitchnet)\n",
    "for j in stitchinfo.joiners:\n",
    "    j[0].active = 0\n",
    "    j[1].active = 0\n",
    "\n",
    "stitchinfo.output_switch.active = 0\n",
    "roa = problem.evaluate_network(dev, stitchneti, objective=\"both\")\n",
    "stitchinfo.output_switch.active = 1\n",
    "rob = problem.evaluate_network(dev, stitchneti, objective=\"both\")\n",
    "roa, rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitchneti = NeuralNetIndividual(stitchnet)\n",
    "for j in stitchinfo.joiners:\n",
    "    j[0].active = 0\n",
    "    j[1].active = 0\n",
    "stitchinfo.output_switch.active = 2\n",
    "j = stitchinfo.joiners[18]\n",
    "# j[0].active = 0\n",
    "# j[1].active = 1\n",
    "j[0].active = 1\n",
    "j[1].active = 0\n",
    "\n",
    "problem.evaluate_network(dev, stitchneti, objective=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recombnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
