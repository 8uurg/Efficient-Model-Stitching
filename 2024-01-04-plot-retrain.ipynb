{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DAEDALUS â€“ Distributed and Automated Evolutionary Deep Architecture Learning with Unprecedented Scalability\n",
    "\n",
    "This research code was developed as part of the research programme Open Technology Programme with project number 18373, which was financed by the Dutch Research Council (NWO), Elekta, and Ortec Logiqcare.\n",
    "\n",
    "Project leaders: Peter A.N. Bosman, Tanja Alderliesten\n",
    "Researchers: Alex Chebykin, Arthur Guijt, Vangelis Kostoulas\n",
    "Main code developer: Arthur Guijt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "# Configure for notebook use.\n",
    "import rpy2.ipython.html\n",
    "rpy2.ipython.html.init_printing()\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(patchwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bound = 0.50\n",
    "# retrained = pl.read_ndjson(\"./imagenet-a-all-evals-front.reeval-train-lr-1e-4.jsonl\")\n",
    "# retrained = pl.read_ndjson(\"./imagenet-a-all-evals-front.reeval-train-lr-1e-4-uf.jsonl\")\n",
    "# retrained = pl.read_ndjson(\"./imagenet-a-all-evals-front.reeval-train-lr-1e-5.jsonl\")\n",
    "# retrained = pl.read_ndjson(\"./imagenet-a-all-evals-front.reeval-train-lr-1e-5-uf.jsonl\")\n",
    "\n",
    "retrained = pl.read_ndjson(\"./imagenet-a-all-evals-front.reeval-train.jsonl\")\n",
    "samples = (retrained.lazy().sort(\"untrained_accuracy\").select([\n",
    "    pl.col(\"untrained_accuracy\").alias(\"untrained accuracy (validation)\"),\n",
    "    pl.col(\"reeval-result\").struct.field(\"trained_val_accuracy\").alias(\"trained accuracy (validation)\"),\n",
    "    pl.col(\"reeval-result\").struct.field(\"untrained_test_accuracy\").alias(\"untrained accuracy (test)\"),\n",
    "    pl.col(\"reeval-result\").struct.field(\"trained_test_accuracy\").alias(\"trained accuracy (test)\"),\n",
    "    pl.col(\"untrained_loss\").alias(\"untrained loss (validation)\"),\n",
    "    pl.col(\"reeval-result\").struct.field(\"trained_val_loss\").alias(\"trained loss (validation)\"),\n",
    "    pl.col(\"reeval-result\").struct.field(\"untrained_test_loss\").alias(\"untrained loss (test)\"),\n",
    "    pl.col(\"reeval-result\").struct.field(\"trained_test_loss\").alias(\"trained loss (test)\"),\n",
    "    pl.col(\"multiply-adds\")\n",
    "])\n",
    "# -Inf out solutions that have broken completely\n",
    ".with_columns([\n",
    "    pl.when(pl.col(\"trained accuracy (validation)\") < min_bound).then(-np.inf).otherwise(pl.col(\"trained accuracy (validation)\")).alias(\"trained accuracy (validation)\"),\n",
    "    pl.when(pl.col(\"trained accuracy (test)\") < min_bound).then(-np.inf).otherwise(pl.col(\"trained accuracy (test)\")).alias(\"trained accuracy (test)\"),\n",
    "    pl.when(pl.col(\"trained loss (validation)\") < min_bound).then(np.inf).otherwise(pl.col(\"trained loss (validation)\")).alias(\"trained loss (validation)\"),\n",
    "    pl.when(pl.col(\"trained loss (test)\") < min_bound).then(np.inf).otherwise(pl.col(\"trained loss (test)\")).alias(\"trained loss (test)\"),\n",
    "])\n",
    ").collect()\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement_direction = {\n",
    "    \"accuracy\": 1,\n",
    "    \"accuracy (validation)\": 1,\n",
    "    \"accuracy (test)\": 1,\n",
    "    \"loss\": -1,\n",
    "    \"loss (validation)\": -1,\n",
    "    \"loss (test)\": -1,\n",
    "    \"loss-clip\": -1,\n",
    "    \"total bytes\": -1,\n",
    "    \"total_memory_bytes\": -1, # dict name\n",
    "    \"multiply-adds\": -1,\n",
    "    \"total_mult_adds\": -1, # dict name\n",
    "    # \"genotype\": 0, # -- not a criterion\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools for computing fronts\n",
    "# TODO: Modify for showing improvement?\n",
    "def maybe_over(a, o):\n",
    "    if len(o) == 0: return a\n",
    "    else: return a.over(o)\n",
    "\n",
    "def compute_pareto(df, group_vars, c0, c1):\n",
    "    return (df.sort(c0, descending=improvement_direction[c0] > 0)\n",
    "        .with_columns((pl.col(c1) * -improvement_direction[c1]).alias(\"c1-min\"))\n",
    "        .with_columns(maybe_over((pl.col(\"c1-min\")).cummin(), group_vars).alias(\"mv\"))\n",
    "        .with_columns((maybe_over(pl.col(\"c1-min\") < pl.col(\"mv\").shift(1), group_vars).alias(\"is pareto\")).fill_null(True))\n",
    "        .filter(pl.col(\"is pareto\"))\n",
    "    )\n",
    "\n",
    "def compute_2d_hv(df_pareto, ref, axis_scale, group_vars, c0, c1):\n",
    "    # note - df_pareto is a df created using compute_pareto\n",
    "    dhva = (df_pareto.sort(c0, descending=improvement_direction[c0] < 0)\n",
    "        # Samples worse than reference point do not contribute.\n",
    "        # .filter(improvement_direction[c0] * pl.col(c0) > improvement_direction[c0] * ref[0])\n",
    "        # .filter(improvement_direction[c1] * pl.col(c1) > improvement_direction[c1] * ref[1])\n",
    "        .with_columns(\n",
    "        [\n",
    "            maybe_over( improvement_direction[c0] * (pl.col(c0) - pl.col(c0).shift(1).fill_null(ref[0])) / axis_scale[0], group_vars).alias(\"slice_width\"),\n",
    "            maybe_over( improvement_direction[c1] * (pl.col(c1) - ref[1]) / axis_scale[1], group_vars).alias(\"slice_height\"),\n",
    "        ])\n",
    "        .select([pl.col(group_vars), (pl.col(\"slice_width\") * pl.col(\"slice_height\")).alias(\"hv_contrib\")])\n",
    "        .group_by(group_vars).agg(pl.col(\"hv_contrib\").sum()))\n",
    "    return dhva\n",
    "\n",
    "def get_transformed_front(per_run_front, grouping, c0, c1):\n",
    "    # Create a dataframe for plotting in R\n",
    "    pd_per_run_front = (per_run_front.lazy()\n",
    "        # Add a tag so that we can track which samples were original - and which ones were added for sake\n",
    "        # of continuing the lines.\n",
    "        .with_columns(pl.lit(1.0).alias(\"is_original\"))\n",
    "        # For each run include an additional two rows:\n",
    "        # Repeat best per objective, but replace the other objective with -Inf - as to plot towards the axes.\n",
    "        .merge_sorted(per_run_front.lazy()\n",
    "                    .with_columns([(pl.col(c0) * improvement_direction[c0]).alias(\"c0-n\"),\n",
    "                                    pl.lit(-np.Inf * improvement_direction[c1]).alias(c1),\n",
    "                                    pl.lit(0.0).alias(\"is_original\")])\n",
    "                    .group_by(grouping, maintain_order=True)\n",
    "                    .agg(pl.all().sort_by(\"c0-n\").last())\n",
    "                    .select(per_run_front.columns + [\"is_original\"]), \"file\")\n",
    "        .merge_sorted(per_run_front.lazy()\n",
    "                    .with_columns([(pl.col(c1) * improvement_direction[c1]).alias(\"c1-n\"),\n",
    "                                    pl.lit(-np.Inf * improvement_direction[c0]).alias(c0),\n",
    "                                    pl.lit(0.0).alias(\"is_original\")])\n",
    "                    .group_by(grouping, maintain_order=True)\n",
    "                    .agg(pl.all().sort_by(\"c1-n\").last())\n",
    "                    .select(per_run_front.columns + [\"is_original\"]), \"file\")\n",
    "        # Add c0 and c1 as a named column\n",
    "        .with_columns([pl.col(c0).alias(\"c0\"), pl.col(c1).alias(\"c1\")])\n",
    "        # Sort, for good measure\n",
    "        .sort(grouping + [c0, c1])\n",
    "        # Collect & convert to pandas in order to transfer.\n",
    "        .collect().to_pandas())\n",
    "    return pd_per_run_front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_pd = samples.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i samples_pd -w 500 -h 270\n",
    "\n",
    "scientific_10 <- function(x) {   parse(text=gsub(\"e\\\\+*\", \" %*% 10^\", scales::scientific_format()(x))) } \n",
    "\n",
    "pla <- ggplot(samples_pd, aes(y = `multiply-adds`, yend = `multiply-adds`)) +\n",
    "    geom_segment(aes(x = `untrained accuracy (validation)`, xend=`trained accuracy (validation)`), arrow = arrow(length = unit(0.02, \"npc\")), alpha=0.3) +\n",
    "    geom_point(aes(x = `untrained accuracy (validation)`), alpha=0.3) +\n",
    "    geom_point(aes(x = `trained accuracy (validation)`), color=\"blue\", shape = 21, fill=NA) +\n",
    "    scale_y_continuous(label=scientific_10) +\n",
    "    labs(x = \"accuracy (validation)\") +\n",
    "    theme_bw() +\n",
    "    theme(\n",
    "      legend.position=\"bottom\",\n",
    "      axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),\n",
    "      plot.background = element_rect(fill='transparent', color=NA),\n",
    "      strip.background = element_blank())\n",
    "\n",
    "plb <- ggplot(samples_pd, aes(y = `multiply-adds`, yend = `multiply-adds`)) +\n",
    "    geom_segment(aes(x = `untrained accuracy (test)`, xend=`trained accuracy (test)`), arrow = arrow(length = unit(0.02, \"npc\")), alpha=0.3) +\n",
    "    geom_point(aes(x = `untrained accuracy (test)`), alpha=0.3) +\n",
    "    geom_point(aes(x = `trained accuracy (test)`), color=\"blue\", shape = 21, fill=NA) +\n",
    "    scale_y_continuous(label=scientific_10) +\n",
    "    labs(x = \"accuracy (test)\") +\n",
    "    theme_bw() +\n",
    "    theme(\n",
    "      legend.position=\"bottom\",\n",
    "      axis.text.y=element_blank(),\n",
    "      axis.title.y=element_blank(),\n",
    "      axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),\n",
    "      plot.background = element_rect(fill='transparent', color=NA),\n",
    "      strip.background = element_blank())\n",
    "\n",
    "plt <- (pla | plb)# + plot_layout(guides = \"collect\") & theme(legend.position=\"bottom\")\n",
    "# ggsave(\"result-retrain.pdf\")\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recombnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
